% !TEX encoding = UTF-8 Unicode

% Compilation using 'acmsmall.cls' - version 1.3 (March 2012), Aptara Inc.
% (c) 2010 Association for Computing Machinery (ACM)
%
% Questions/Suggestions/Feedback should be addressed to => "acmtexsupport@aptaracorp.com".
% Users can also go through the FAQs available on the journal's submission webpage.
%
% Steps to compile: latex, bibtex, latex, latex


\documentclass[prodmode,acmtochi]{acmsmall} % Aptara syntax

% Package to generate and customize Algorithm as per ACM style
\usepackage[ruled]{algorithm2e}
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

% Packages
\usepackage[super]{nth}
\usepackage[inline]{enumitem}
\usepackage{moreenum}
\usepackage{tabulary}
\usepackage{tabu}
\usepackage{booktabs}
\usepackage{array}
\usepackage[super]{nth}
\usepackage{listings}
\usepackage{float}
\usepackage{minted}
\usemintedstyle{bw}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
%\newcommand{\urlhttp}[1]{\href{http://#1}{\nolinkurl{#1}}}
%\newcommand{\urlhttps}[1]{\href{https://#1}{\nolinkurl{#1}}}

% Special characters
\usepackage{amssymb}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}

% Metadata Information
\acmVolume{0}
\acmNumber{0}
\acmArticle{0}
\acmYear{0}
\acmMonth{0}

% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
\doi{0000001.0000001}

%ISSN
\issn{1234-56789}

% Document starts
\begin{document}

% Page heads
\markboth{B. Harmon et al.}{Cognitively Grasping Topography with Tangible Landscape}

% Title portion
\title{Cognitively Grasping Topography with Tangible Landscape} 
% Cognitively Grasping 3D Form with Tangible Landscape
% Multidimensional Sketching with Tangible Landscape
% Embodied Spatial Cognition in Tangible Computing
% Cognitively Grasping Topography with Tangible Landscape
% Tangible Landscape: Cognitively Grasping Topography
% Tangible Landscape: a Tangible Interface for Geospatial Modeling
% Tangible Landscape: Cognitively Grasping Topography with a Tangible Interface for Geospatial Modeling
% Tangible Landscape: a 3D Sketching with a Tangible Interface for Geospatial Modeling
% 
\author{BRENDAN ALEXANDER HARMON
\affil{North Carolina State University}
ANNA PETRASOVA
\affil{North Carolina State University}
VACLAV PETRAS
\affil{North Carolina State University}
HELENA MITASOVA
\affil{North Carolina State University}
ROSS â€‹KENDALL MEENTEMEYER
\affil{North Carolina State University}
EUGENE BRESSLER
\affil{North Carolina State University}
ART RICE
\affil{North Carolina State University}}

\begin{abstract}
%
Spatial thinking can be embodied 
-- people can functionally think about space with their bodies 
by kinaesthetically experiencing space, 
cognitively grasping objects, and 
physically simulating spatial transformations.
%
Tangible interfaces for spatial modeling
combine kinaesthetic interaction with spatial computations. 
%
Theoretically this should enable users to 
naturally and intuitively interact 
with multidimensional digital models of space,
offloading challenging cognitive tasks onto the body and 
computationally enhancing how they think about space.
% 
We have designed Tangible Landscape 
-- a tangible interface powered by a geographic information system (GIS) -- 
that gives 3D spatial data an interactive, physical form so that 
users can naturally feel it, see it, and shape it.
%
Tangible Landscape couples a physical and a digital model of a landscape
through continual near real-time cycles of 
physical manipulation, 3D scanning, spatial computation, and projected feedback.
%
As users manipulate
a physical model of a landscape
the model is 3D scanned, the scan is imported into GIS 
for spatial modeling, analysis, and simulation, 
and the results are projected back onto the model.
%
%Coupling physical and digital models 
%should, theoretically, enable 
%users to cognitively grasp 3D data 
%as an extension of their bodies 
%and automatically, immediately, and subconsciously interact with it. 
% 
We conducted a series of experiments using 
quantitative methods 
including geospatial modeling, analysis, simulation, and statistics 
and qualitative methods 
including semi-structured interviews and direct observation
to study how tangible interfaces for geospatial modeling 
mediate spatial performance. 
%
We determined that tangible interfaces for geospatial modeling 
can improve 3D spatial performance.
%
In the experiments participants produced more accurate models 
that better represented morphological features 
with tangible modeling than they did with either digital or analog, hand modeling. 
%
%We also ran a serious gaming event as a case study
%in which attendees used Tangible Landscape to solve complex spatial problems. 
%As they played the games
%attendees naturally steered sophisticated simulations of environmental processes,
%iteratively exploring and learning how the processes behave. 
%
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003120.10003121</concept_id>
<concept_desc>Human-centered computing~Human computer interaction (HCI)</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003120.10003121.10003122.10011749</concept_id>
<concept_desc>Human-centered computing~Laboratory experiments</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Human computer interaction (HCI)}
\ccsdesc[500]{Human-centered computing~Laboratory experiments}
%
% End generated code
%

\keywords{Human-computer interaction, tangible interfaces, interaction design, physical computation, embodied cognition, spatial thinking, geospatial modeling}

\acmformat{Brendan A. Harmon, Anna Petrasova, Vaclav Petras, Helena Mitasova, Ross K. Meentemeyer, Eugene H. Bressler, and Art Rice, 2016. Embodied Spatial Cognition in Tangible Computing.}

\begin{bottomstuff}
Author's addresses: B. A. Harmon {and} A. Petrasova {and} V. Petras {and} H. Mitasova {and} R. K. Meentemeyer, Center for Geospatial Analytics, North Carolina State University; B. A. Harmon, E. H. Bressler {and} A. Rice, Department of Landscape Architecture, North Carolina State University.
\end{bottomstuff}


\maketitle

\section{Introduction}

\begin{figure}
\begin{center}
%		\includegraphics[width=0.32\textwidth]{images/tl_sequence_1.jpg}
		\includegraphics[width=0.49\textwidth]{images/tl_sequence_2.jpg}
		\includegraphics[width=0.49\textwidth]{images/tl_sequence_3.jpg}
	\caption{Tangibly modeling the flow of water with Tangible Landscape. 
	A user sculpts a polymeric sand model of a landscape
	augmented with simulated water flow and an orthophotograph.  
	Changes to the model are scanned into in GIS 
	and the resulting water flow simulation is
	projected back onto the model in near real-time.}
	\label{fig:tl_flow}
\end{center}
\end{figure}

Geographic information systems (GIS) 
can be used to quantitatively model, analyze, simulate, and visualize 
complex spatial and temporal phenomena 
-- computationally enhancing users' understanding of space. 
%
With extensive libraries for point cloud processing, 
3D vector modeling, and
surface and volumetric modeling and analysis
GIS are powerful tools for studying 3-dimensional (3D) space.
%
GIS, however, can be unintuitive and challenging to use \cite{Ratti2004}. 
% more citations? % Goodchild 2011 % Buckley et al. 2000
%
Unintuitive interactions with GIS can 
frustrate users,
constrain how they think about space,
and add new cognitive burdens
requiring highly developed spatial skills and reasoning. 
%
Since visually thinking about 3D space requires
sophisticated spatial abilities like mental rotation, 
it can be especially challenging to understand and manipulate 3D space
in a GIS using a graphical user interface (GUI).
%
In order to make 3D GIS more natural and intuitive to use
we have designed Tangible Landscape 
-- a tangible interface for GIS --
that physically manifests 3D data 
so that users can feel and manipulate it with their bodies 
(Fig.~\ref{fig:tl_flow}). 
%
We designed Tangible Landscape
so that
users can hold a GIS in their hands
and think about 
3D space and spatial computations
kinaesthetically with their bodies.
%
Our goal is for users with little or no computer experience 
to be able to intuitively, collaboratively explore 
%higher dimensional %multidimensional 
3D spatial data 
and interact with scientific models
so that they can 
rapidly test ideas while learning from computational feedback. 
%
We have begun to
quantitatively analyze how 
Tangible Landscape mediates 3D spatial cognition. 
%
We invite other researchers to collaborate 
in this ongoing open source and open science project 
by building Tangible Landscape,
contributing to its development,
developing new applications, 
and studying how it mediates cognition. 

\subsection{Spatial thinking and computation} % 3D 
Spatial thinking -- `the mental processes of representing, analyzing, and drawing inferences from spatial relations' \cite{Uttal2013} -- is used pervasively in everyday life for tasks such as recognizing things, manipulating things, interacting with others, and way-finding. 
% 
Higher dimensional spatial thinking 
-- thinking about form, volume, and processes unfolding in time -- 
plays an important role in 
science, technology, engineering, the arts, and math. 
%
3D spatial thinking is used in disciplines 
such as geology to understand the structure of the earth, 
ecology to understand the structure of ecosystems, 
civil engineering to shape landscapes, 
architecture to design buildings,
urban planning to model cities,
and the arts to shape sculpture.

% spatial concepts
Conceptually understanding 3D space 
-- especially at a geographic scale --
requires sophisticated reasoning.
%
% Nystuen (1963)
% Papageourgiou (1969)
% Gersmehl and Gersmehl
% Golledge
%
In Gollegde et al.'s hierarchical framework of concepts 
for thinking about geographic space,
primitive concepts -- identity and location, magnitude, and space-time --
form the basis of geographic knowledge \cite{Golledge2002,Golledge2016}. 
%
%Concepts of increasing complexity are derived from 
%combinations of simpler concepts. 
%
In this framework
3D surfaces 
are a complicated concept
derived from 
primitives (location and magnitude) and
simple concepts (distribution, relative distance, and shape).
%and difficult concepts (area). 
%
Understanding how 3D surfaces like topography 
control processes like the flow of water
requires even more complex conceptual thinking
building upon primitives (identity, location, magnitude, and space-time),
simple concepts (distribution, relative distance, direction, sequence, and shape), 
difficult concepts (area, change, and spread),
and complicated concepts (gradient, connectivity, scale, and surface).
%
%Cognitive studies have shown that 
%`spatial thinking is malleable,' 
%that it can be improved be through training
%\cite{Uttal2013}.
%
% `Spatial thinking is malleable ' \cite{Uttal2013}.
%
Given the importance of higher dimensional spatial thinking 
how can we effectively improve spatial performance --
the ability to perform tasks that require spatial thinking --
for complex tasks in 3D space? 

Many spatial tasks can be performed computationally 
enabling us to efficiently store, model, and analyze large sets of spatial data 
and solve complex spatiotemporal problems.
%
In engineering, design, and the arts 
computer-aided design (CAD) and 3D modeling software are used to interactively, computationally model, analyze, and animate complex 3D forms. 
%
Multidimensional spatial patterns and processes can be 
mathematically modeled, simulated, and optimized 
through scientific computing.
%
Geographic information systems for example can be used 
to computationally store, model, analyze, simulate, and represent 
geospatial patterns and processes. 
%
The open source 
Geographic Resource Analysis Support System (GRASS) GIS for example supports 
`geospatial data management and analysis, image processing, graphics and maps production, spatial modeling, and visualization' \cite{GRASS_GIS_software}. 

Computing mediates and transforms spatial thinking -- expanding, but also constraining what is possible.
%
While spatial computing can augment spatial thinking 
-- distributing or offloading cognitive processes through digital computation -- 
the logic of implementation,
the limits of what is computationally possible, 
and the modes of input and output
constrain how we reason. % citations
%
Furthermore, 
when it is difficult to interact with a computer, 
to input commands and parse the resulting output, 
one has to think harder 
and risks frustration and demotivation. % citations 

Unintuitive modes of human-computer interaction constrain thought and add cognitive and emotional costs. 
%
The paradigmatic modes for interacting with computers today 
-- command line interfaces (CLI) and
graphical user interfaces
 -- 
require physical input from devices like keyboards, mice, digitizing pens, and touch screens, but
output %render
data visually as text or graphics. 
%
Theoretically this disconnect between intention, action, and feedback should make interaction less intuitive \cite{Dourish2001,Ishii2008}. 
%
Furthermore, it can also be challenging to parse data that is only presented visually. 
Spatial data -- especially 3D spatial data -- presented graphically can require sophisticated spatial reasoning skills such as mental rotation \cite{Shepard1971}, spatial visualization, and spatial perception \cite{Linn1985} to parse and understand, much less manipulate. 

\subsection{Tangible interaction}

% Introduction to tangible interfaces
Tangible interfaces -- interfaces that couple physical and digital data \cite{Dourish2001} -- 
are designed to physically manifest digital data so that we can cognitively grasp and absorb it,
so that we can think with it rather than about it \cite{Kirsh2013}. 
%
Ishii and Ullmer envisioned that tangible interfaces would  `take advantage of natural physical affordances to achieve a heightened legibility and seamlessness of interaction between people and information' \cite{Ishii1997}. 
%
With a tangible interface both input and output are physical. 
%
Data can be felt as well as seen; data can be directly, physically manipulated, leveraging highly developed motor skills. 
%
Thus intention, action, and feedback should be seamlessly connected 
enabling automatic, subconscious, and intuitive interaction.

% Embodied interaction
Tangible interfaces let users interact with computers while (functionally) thinking with their bodies. 
%
By thinking with their bodies, by embodying cognition 
users may be able to reduce their cognitive loads
offloading cognitive tasks like 
spatial perception and manipulation 
onto the body and 
physically simulating processes.
%
In embodied cognition higher cognitive processes are grounded in, built upon, and mediated by bodily experiences such as kinaesthetic perception and action \cite{Hardy-Vallee2008}. 
%
When people use tools they temporarily, contingently incorporate them into their body schema, feeling the perimeter, weight, and balance of the tool, 
sensing resistance when the tool touches something, 
as if the tool was an extension of the body \cite{Maravita2004}.
%
Because tools can be cognitively gripped and absorbed into users' body schema, tools mediate embodied cognition -- affording new bodily experiences and actions and thus extending users' capacity for thought. 
%
Tangible interfaces are designed to give computation physical form 
so that it can be cognitively gripped and absorbed, 
so that computation can be understood with and offloaded onto the body.
%
When tangible interactions are designed to be analogous to everyday, physical tasks 
like unscrewing a bottle top \cite{Kirsh2013}, 
picking up and placing objects, 
or sculpting sand 
users may already understand what to do; 
such interaction should be highly intuitive
drawing on existing cultural knowledge and motor schemas. 

% Tangible interaction and spatial cognition
It can be challenging and cognitively taxing to visually perceive and parse space, to for example visually judge distances and imagine volumetric form.
%
Distance and physical properties like size, shape, volume, weight, hardness, and texture, however, can be automatically and subconsciously assessed kinaesthetically with the body \cite{Jeannerod1997}. 
%
By affording physical feedback tangible interfaces should, therefore, reduce the cognitive load needed to judge and manipulate spatial distances, relationships, patterns, and 3D forms and volumes. 

\begin{figure}
\begin{center}
		\includegraphics[width=0.49\textwidth]{images/physical_rotation_1.jpg}
		\includegraphics[width=0.49\textwidth]{images/physical_rotation_2.jpg}
	\caption{Physically rotating a topographic model.}
	\label{fig:physical_rotation}
\end{center}
\end{figure}

% Physical simulation
Furthermore, some cognitive processes can be physically simulated, offloading cognitive work onto the body \cite{Kirsh2013}. 
%
Mental models can be abstracted and physically simulated 
through acting, 
sketching, 
or experimental adaptation or transformation. 
%
Kirsh cites dancers use of marking 
-- a simplified, abstraction of a dance phrase -- 
to learn and practice elements or aspects of the phrase \cite{Kirsh2013}. 
%
% Mental rotation
Mental rotation 
-- a cognitive task commonly used in psychometric tests of spatial ability -- 
can be physically simulated 
simply by grasping the object and rotating it (Fig.~\ref{fig:physical_rotation}).
%
While tasks like spatial visualization and mental rotation are used assess spatial ability
\cite{Uttal2013a,Uttal2013,Ormand2014}, 
space is not just visualized, but also felt.
Space need not be imagined to be transformed. 
%--haptic feedback about space informs subconscious pragmatic representations that rapidly generate action \cite{Jeannerod1997}. 
Mental rotation and spatial visualization, therefore, 
may tell us very little about embodied spatial ability. 

% Form finding
Metacognition -- thinking about thinking -- 
can play an important role in embodied spatial performance.
%
Physical simulation guided by metacognitive reflection 
is used in generative, creative processes 
such as sculptural form-finding or gestural sketching. 
%
Professionals like designers develop creative ideas through `reflection-in-action,' 
an iterative, exploratory, metacognitive process 
of framing a problem, ideation or making, and critical reflection \cite{Schon1983}.
This exploratory process may unfold in an instant, 
repeated continually throughout acts such as drawing, sculpting, and modeling. 
%
The architect Frank Gehry for example develops his designs through exploratory form finding with massing models
and by thinking through the movement of gestural drawing
\cite{Gehry2004,Pollack2006}.
%
An ethnography of the Office of Metropolitan Architecture
showed that architects in the firm used exploratory modeling
to develop designs through iterative processes
-- exploring form by carving foam massing models with hot-wire cutters, reflecting on each model as they carved, while building up a library of forms \cite{Yaneva2009}.

% Metacognition in tangible interaction
Tangible interfaces enable embodied interaction
-- the kinaesthetic exploration and physical transformation of digital data.
%
By embodying interaction
users should be able to offload 
challenging cognitive tasks 
like sensing form, manipulating form, and imagining new forms 
onto the body
-- freeing up more cognitive resources for  
metacognition. 
%
With more resources for metacognition
users should be better able to parse and learn from computations.

\subsection{Tangible interfaces for geospatial modeling} 
% Tangible geospatial interaction
% Tangible geospatial modeling
% Tangible interfaces for geospatial modeling

With GIS %spatial modeling
users can computationally offload other types of challenging cognitive tasks 
like analyzing spatial patterns and simulating spatiotemporal processes.
%
Tangible interfaces for geospatial modeling should, 
therefore, enhance users' spatial performance 
for challenging tasks 
like sculpting topography and guiding the flow of water
by combining these physical and computational affordances.
%
There are already many tangible interfaces for geospatial modeling.
%
%Tangible interfaces for geospatial modeling 
These include 
augmented architectural models (Table~\ref{table:review_a}), 
augmented clay (Table~\ref{table:review_b}),  
augmented sandboxes (Table~\ref{table:review_c}), 
and actuated pin tables (Table~\ref{table:review_d}).
%
Projection augmented tangible interfaces 
couple a physical and digital model
through a cycle of 3D sensing or object recognition,
computation, and projection. 
%
Augmented architectural models
like Urp \cite{Underkoffler1999} 
and the Collaborative Design Platform \cite{Schubert2011}
are a type of 
`discrete tabletop tangible interface' \cite{Ishii2012}.
%
Augmented clay models 
like Illuminating Clay \cite{Piper2002a} 
and augmented sandboxes like Sandscape \cite{Ishii2004} 
are types of 
`deformable, continuous tangible interfaces' \cite{Ishii2012}
that users can sculpt. 
%
These tangible interfaces 
have two feedback loops -- 
there is passive, kinaesthetic feedback from grasping the physical model 
and active, graphical feedback from computation.
%
Actuated pin tables
like Relief \cite{Leithinger2009}
are a type of transformable tangible interface \cite{Ishii2012} 
or shape changing interface
which use `physical change of shape as input or output' \cite{Rasmussen2012}. 
%
These tangible interfaces 
have a third feedback loop --
the physical model
can be computationally transformed
for active, kinaesthetic feedback. 

Research on tangible interfaces for geospatial modeling 
has focused on the design of new technologies and prototypes
rather than studying how they
are used. 
%
A review of tangible interfaces for geospatial modeling 
(Tables~\ref{table:review_a}-\ref{table:review_d})
shows that have been 
relatively few case studies \cite{Ishii2002,Tateosian2010,Petrasova2015} 
or qualitative user studies \cite{Shamonsky2003}
and only a single quantitive pilot study \cite{Harmon2016}.
%
A review of shape-changing interfaces 
also found that there were relatively few user studies
and called for `more, high-quality data on user experience'
in order to understand if interfaces work as designed
\cite{Rasmussen2012}.

Many of the theoretical underpinnings of tangibles 
remain unproven and unexplored. 
%
Can users successfully
cognitively grasp digital data as an extension of their bodies,
intuitively interact, 
and offload cognitive processes
with tangibles?
%
How does this change how users think and perform?
%
Do current approaches to tangible, embodied interfaces
really work as theorized? 

Because bodies are situated in space, embodiment is inherently spatial. 
%
Tangible, embodied interaction could radically change 
how we think about and interact with space in computing. 
%
Tangible interfaces for geospatial modeling 
promise to enhance spatial thinking
through kinaesthetic interaction with 
spatial computations. 
%
How can tangible interfaces for geospatial modeling 
mediate spatial cognition and performance? 
%
Can users offload enough cognitive work onto their bodies
with tangible interfaces for geospatial modeling 
to successfully parse and learn from computational feedback
without suffering cognitive overload?
%

In order to begin to answer some of these questions we 
designed a tangible interface for geospatial modeling, 
while simultaneously conducting an experiment
to study how this tangible interface mediates spatial cognition.
%
Our research objectives were to:
%
\begin{itemize}
\item Design an effective tangible interface for geospatial modeling
\item Test whether coupling a physical and digital model of topography can improve spatial performance
\item Study how different geospatial analytics mediate users' spatial performance when using a tangible interface for geospatial modeling
\end{itemize}


\begin{table}
\tbl{Augmented architectural modeling interfaces}{
\ra{1.5}
\begin{tabulary}{1.0\textwidth}{LLCLL}
\toprule
System & \mbox{Interaction} & GIS & User studies & Publications\\
\midrule
%
Urp & Object detection && \mbox{Case studies\textsuperscript{\textasteriskcentered}} & \cite{Underkoffler1999}\\
&&&& \cite{Ishii2002}\textsuperscript{\textasteriskcentered}\\
%
Collaborative Design Platform & Object detection &&& \cite{Schubert2011}\\
& Touch &&& \cite{Schubert2011a}\\
& Sketching &&&  \cite{Schubert2012}\\
&&&& \cite{Schubert2014}\\
&&&& \cite{Schubert2015}\\
%&&&& \cite{Schubert2013}\\
%&&&& \cite{Schubert2014a}\\
%
\bottomrule
\end{tabulary}}
\label{table:review_a} 
%
\vspace*{1.5em}
%
\tbl{Augmented clay interfaces}{
\ra{1.5}
\begin{tabulary}{1.0\textwidth}{LLLCLL}
\toprule
System & \mbox{Interaction} & GIS & User studies & Publications\\
\midrule
%
Illuminating Clay & Sculpting && Protocol analysis\textsuperscript{\textdaggerdbl} & \cite{Piper2002a}\\
&&&& \cite{Piper2002b}\\
&&&& \cite{fielding-piper2002}\\
&&&& \cite{Shamonsky2003}\textsuperscript{\textdaggerdbl}\\
&&&& \cite{Ishii2004}\\
&&&& \cite{Ratti2004}\\
%
Tangible Geospatial Modeling System & Sculpting & \cmark & Case studies\textsuperscript{\textasteriskcentered} & \cite{Mitasova2006}\\
&&&& \cite{Tateosian2010}\textsuperscript{\textasteriskcentered}\\
%
\bottomrule
\end{tabulary}}
\label{table:review_b} 
%
\vspace*{1.5em}
%
\tbl{Augmented sandbox interfaces}{
\ra{1.5}
\begin{tabulary}{1.0\textwidth}{LLLCLL}
\toprule
System & \mbox{Interaction} & GIS & User studies & Publications\\
\midrule
%
SandScape& Sculpting &&& \cite{Ishii2004}\\
&&&& \cite{Ratti2004}\\
%
SandyStation & Sculpting &&&\\ 
%
Augmented Reality Sandbox & Sculpting &&& \cite{Reed2014}\\
& Gesture\\
%
Tangible Landscape & Sculpting & \cmark & Case studies\textsuperscript{\textasteriskcentered} & \cite{Petrasova2014}\\
& Object detection && Quantitative experiments\textsuperscript{\textdagger} & \cite{Petrasova2015}\textsuperscript{\textasteriskcentered}\\
& Sketching &&& \cite{Harmon2016}\textsuperscript{\textdagger}\\
%&&&& \cite{Harmon2016a}\\
%
The Augmented REality Sandtable (ARES) & Sculpting &&& \cite{Amburn2015}\\
& Gesture\\
%
\bottomrule
\end{tabulary}}
\label{table:review_c} 
\end{table}
%
\begin{table}
\tbl{Actuated pin table interfaces}{
\ra{1.5}
\begin{tabulary}{1.0\textwidth}{LLCLL}
\toprule
System & \mbox{Interaction} & GIS & User studies & Publications\\
\midrule
%
XenoVision Mark III Dynamic Sand Table & Sculpting &&&\\
%
Northrop Grumman Terrain Table & Sculpting &&&\\
%
Relief & Sculpting &&& \cite{Leithinger2009}\\
&&&& \cite{Leithinger2010}\\
%
Recompose & Sculpting &&& \cite{Leithinger2011}\\
& Gesture &&& \cite{Blackshaw2011}\\
%
Tangible CityScape & Gesture &&&\\
% 
Inform & Sculpting &&& \cite{Follmer2013}\\
& Gesture\\
& Object detection\\
%
\bottomrule
\end{tabulary}}
\label{table:review_d} 
\end{table}

\section{Tangible Landscape}

\subsection{Concept}
%
Tangible interfaces for GIS 
should ease the cognitive burden of 
visualizing, interacting with, 
and reasoning about space
by giving spatial data an interactive, physical form 
that users can cognitively grasp and kinaesthetically explore. 
%
Tangible Landscape -- a tangible user interface for GRASS GIS --
couples a physical and digital model of a landscape through a continuous cycle of 3D scanning, geospatial modeling, and projection
so that users can intuitively interact with the modeled landscape in near real-time.
%
Conceptually Tangible Landscape physically manifests 3D data 
so that users can hold a GIS in their hands -- 
so that they can, for example, feel the shape of the earth, sculpt its topography, and direct the flow of water with their hands.
%
It enables users to 3D sketch -- 
to naturally model forms such as topography, 
draw points and polygons, 
and interact with simulated physical processes -- 
in a rapid, iterative process 
of observation, hypothesis generation and testing, and inference. 
%
Tangible Landscape is meant to fluidly, seamlessly combine
computational science with exploratory modes of creative thinking.

\subsection{Evolution}
Tangible Landscape evolved from 
Illuminating Clay \cite{Piper2002a} and 
the Tangible Geospatial Modeling System (TanGeoMS) \cite{Tateosian2010}. 
% Illuminating Clay
Illuminating Clay coupled a clay model and digital model of landscape 
through a cycle of laser scanning, spatial modeling, and projection.
By enriching physical models of urban spaces and landscapes 
with spatial analyses  
such as 
elevation, aspect, slope, cast shadow, profile, curvature, 
viewsheds, solar irradiation, and water direction
it enabled
intuitive form-finding, 
streamlined analog and digital workflows, 
and enabled multiple users to simultaneously interact in a natural way \cite{Ratti2004}. 
Illuminating Clay had a very limited library of custom implemented spatial analyses. 
Since many of analyses were adapted 
from the open source GRASS GIS project \cite{Piper2002a} 
there was a call for closer integration with GRASS GIS 
in order to draw on its extensive libraries 
for spatial computation \cite{Piper2002b}. 
The effort to couple a physical landscape model with GRASS GIS \cite{Mitasova2006} 
led to the development of 
TanGeoMS \cite{Tateosian2010}.

% Tangible Geospatial Modeling System
TanGeoMS coupled a physical model and GIS model of a landscape 
through a cycle of laser scanning, 
geospatial computation in GRASS GIS, and projection
giving developers and users assess to 
a sophisticated library for 
spatial modeling, simulation, visualization, and databasing.
It enriched freeform hand modeling with geospatial simulations 
like diffusive water flow and erosion-deposition 
so that users could easily explore how 
changes in topographic form affect landscape processes. 

% Augmented Reality Sandbox
Tangible Landscape -- the next generation of this system -- was inspired by
the open source Augmented Reality Sandbox \cite{Kreylos2012}
which couples a sandbox with a digital model of a landscape 
through a real-time cycle of 3D scanning with a Kinect sensor, spatial modeling and simulation, and projection.
% TL
While TanGeoMS used an expensive laser scanner
for 3D sensing \cite{Tateosian2010}, 
Tangible Landscape uses a low-cost 3D sensor %like the Kinect 
for real-time depth and color sensing. 
The \nth{1} generation of Tangible Landscape \cite{Petrasova2014} 
used the \nth{1} generation Kinect with structured light sensing \cite{Smisek2011}, 
while the \nth{2}  \cite{Petrasova2015} and \nth{3} generations of Tangible Landscape 
used the \nth{2} generation Kinect with time-of-flight sensing \cite{Bamji2015}. 


\subsection{Design}
Tangible Landscape was designed to let users naturally explore 
spatial data, models, and simulations in an engaging, playful way
by 3D sketching (Fig.~\ref{fig:subsurface}). 
Users can work collaboratively, 
simultaneously interacting with the physical model 
(Fig.~\ref{fig:collaboration}). 
As users change the physical model
the model is 3D scanned as a point cloud, georeferenced, imported into GIS, 
and either binned or interpolated as a digital elevation model. 
The digital elevation model is used to compute 
geospatial analyses, models, and simulations, 
which are then projected back onto the physical model 
-- all in near real-time (Fig.~\ref{fig:system_schema}). 
Users can tangibly interact with digital models and simulations
by sculpting, placing objects, or sketching.
They can sculpt the model with their hands
to shape topography, 
create or move volumes
like buildings or forest canopy, 
or explore 3D raster data.  
They can place objects or markers 
that will be identified using object and color recognition
in order to draw points, polylines, polygons, or volumes. 
They can also use a laser pointer to draw polylines or polygons
that will be detected based on light intensity (Fig.~\ref{fig:drawing_trees}). 
As the digital models and simulations update
the results are projected back onto the model for users to see. 
% VR
The results can also be rendered in 3D 
on a screen or head-mounted display like an Oculus Rift
so that users can immersively visualize the modeled landscape 
at a human scale 
(Fig.~\ref{fig:drawing_trees}).
% add reference to immersive tangible geospatial modeling \cite{Payam2016}

\begin{figure}
\begin{center}
		\includegraphics{images/system_schema.pdf}
	\caption{How Tangible Landscape works: a near real-time feedback cycle of interaction, 3D scanning, point cloud processing, geospatial computation, and projection.}
	\label{fig:system_schema}
\end{center}
\end{figure}

Because the model is continually scanned
users' hands will be digitized as they sculpt or place objects. 
Scanning users' hands as topography can be distracting; 
it also, however, helps users understand how the system works
%-- by seeing how direct interaction is --
and encourages play. 
Users can, for example, cup their hands over the model 
and see them fill with simulated water. 
% add figure with example

\paragraph{Multidimensional sketching}
%
Tangible Landscape was designed to enable tangible multidimensional sketching
in geographic space and time. 
%
With Tangible Landscape users can sketch in 3D
by sculpting surfaces or volumes,
drawing across surfaces, 
or placing and manipulating 3D objects.
%
By directly manipulating 3D form 
users can indirectly shape other dependent dimensions of data 
such as simulated processes. 
%
Each scan can be stored, timestamped, and registered
as a space time raster or vector dataset % spatiotemporal dataset
in GRASS GIS' temporal framework
to create a time series of maps. 
%
With this time series users can animate the evolution of their model using the module 
\emph{g.gui.animation}\cite{g.gui.animation}.
%\footnote{\url{https://grass.osgeo.org/grass72/manuals/g.gui.animation.html}}.

% add animated video with example

Advances in virtual reality are enabling immersive 3D sketching.
%
The illustrator
Wesley Allsbrook, %and the Oculus Story Studio team have
for example, 
has drawn an animated short film called Dear Angelica
by sketching in 3D space using the Oculus Rift and Oculus Touch
to combine the affordances of digital painting and physical sculpture \cite{Oculus2016,Quilez2016}. 
%
While this sort of immersive 3D sketching is situated in a fully virtual space,
tangible 3D sketching is situated in a real, but digitally augmented space. 
%
Tangible 3D sketching
can be situated in a collaborative social context
and may not require any new skills -- 
for tangible interactions 
%such as 3D sketching 
can be analogous to everyday actions, 
making use of existing motor schema.
%
While these approaches to 3D sketching 
should theoretically offer very different affordances
in terms of embodied and situated cognition
both have the potential to revolutionize how we 
express ourselves in space and time.

\begin{figure}
\begin{center}
		\includegraphics[height=70px]{images/subsurface_1.jpg}
		\includegraphics[height=70px]{images/subsurface_2.jpg}
		\includegraphics[height=70px]{images/subsurface_3.jpg}
	\caption{Naturally exploring subsurface soil moisture and soil types with Tangible Landscape.}
	\label{fig:subsurface}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
		\includegraphics[width=0.32\textwidth]{images/immersive/sculpting_lakes_2.png}
		\includegraphics[width=0.32\textwidth]{images/immersive/sculpting_landforms_2.png}
		\includegraphics[width=0.32\textwidth]{images/immersive/sculpting_landforms_3.png}
	\caption{Collaboratively sculpting topography and creating lakes with Tangible Landscape.}
	\label{fig:collaboration}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
		\includegraphics[width=0.32\textwidth]{images/immersive/drawing_trees_1.png}
		\includegraphics[width=0.32\textwidth]{images/immersive/drawing_trees_2.png}
		\includegraphics[width=0.32\textwidth]{images/immersive/trees_with_oculus_1.png}
		%\includegraphics[width=0.32\textwidth]{images/immersive/walkthrough_2.png}
	\caption{Drawing and visualizing trees using a laser pointer with Tangible Landscape and an Oculus Rift.}
	\label{fig:drawing_trees}
\end{center}
\end{figure}

\subsection{Implementation}
Tangible Landscape has been implemented as a set of components 
-- the \emph{r.in.kinect} add-on module \cite{r.in.kinect}
%\footnote{\url{https://github.com/tangible-landscape/r.in.kinect}}
and the \emph{grass-tangible-landscape} plugin \cite{grass-tangible-landscape}
%\footnote{\url{https://github.com/tangible-landscape/grass-tangible-landscape}}
--
for the active development version of GRASS GIS (Fig.~\ref{fig:software_schema}). 
The \emph{r.in.kinect} add-on module imports point cloud data from the \nth{2} generation Kinect into GRASS GIS as raster or vector maps. 
It has been implemented as a separate component so that it can easily be used for other applications.
The \emph{grass-tangible-landscape} plugin provides 
utilities, a library of analyses, and a GUI dialog for tangible interaction in GRASS GIS.
The \emph{tangible-landscape-immersive-extension} \cite{tangible-landscape-immersive-extension}
%\footnote{\url{https://github.com/tangible-landscape/tangible-landscape-immersive-extension}}
links Tangible Landscape with Blender, 
an open source 3D modeling and animation program \cite{Blender} 
enabling 3D rendering on screens or head-mounted displays.

Users can develop new analyses for Tangible Landscape 
using the GRASS GIS Python Scripting Library.  %GRASS GIS Python API
Since many tasks in GIS are not appropriate for tangible interaction
Tangible Landscape was designed to supplement, 
not replace GRASS GIS's GUI, CLI, and scripting application program interface (API). 
Tangible Landscape currently runs on Linux and Mac OSX 
with an unsupported branch for Windows. 
Dependencies include the Point Cloud Library \cite{Rusu2011,PCL}, 
OpenKinect's libfreenect2 \cite{OpenKinect}, 
OpenCV \cite{OpenCV},  
watchdog \cite{watchdog}, 
and GRASS GIS \cite{GRASS_GIS_software}.

\begin{figure}
\begin{center}
		\includegraphics{images/software-schema.pdf}
	\caption{Software schema.}
	\label{fig:software_schema}
\end{center}
\end{figure}

\subsection{Fabrication}
We typically use familiar, everyday materials 
-- like sand and wooden blocks -- 
for modeling with Tangible Landscape. 
Interactions -- like sculpting sand and moving wooden blocks -- 
are analogous to everyday tasks
so users should subconsciously know what to do and how to do it, 
leveraging existing sensorimotor schemas. 
The materiality -- the feel, look, and physics -- of the media matters. 
The choice of material can afford different interactions
and mediate meaning, emotion, and motivation. 
We typically use a polymer-enriched sand for the physical terrain model
so that users can easily sculpt forms in a deformable medium 
that will hold its shape, has good plasticity, and has a familiar feel and aesthetic. 
Digital fabrication technologies 
like computer numeric control (CNC) manufacturing and 3D printing
can be used to create molds for casting polymer-enriched sand 
into precise yet deformable models (Fig.~\ref{fig:casting}). 
Cast sand models can precisely represent complex forms 
that are challenging to model by hand 
and can easily be re-cast after use.

Tangible Landscape can be also be used as a modeling aid for sculpting.
Static projections or dynamic analytics like differencing or water flow 
can be used as guides for hand sculpting terrain models. 
Users can project their target digital elevation model and contours 
over their polymeric sand model as a static guide for sculpting. 
Tangible Landscape can also dynamically compute the difference -- i.e.\ cut and fill --
between the target digital elevation model and the scanned model that has been sculpted . 
The difference can provide a real-time guide 
where to add or remove sand in order to match the target digital elevation model (Fig.~\ref{fig:difference_sequence}). 

\begin{figure}
\begin{center}
		\includegraphics[width=0.32\textwidth]{images/3d_print/3d_print_1.jpg}
		\includegraphics[width=0.32\textwidth]{images/3d_print/3d_print_2.jpg}
		\includegraphics[width=0.32\textwidth]{images/3d_print/3d_print_3.jpg}
	\caption{Casting polymeric sand models with 3D printed molds. Source: \cite{Petrasova2015}.}
	\label{fig:casting}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
		\includegraphics[width=0.49\textwidth]{images/difference/tl_difference_1.jpg}
		\includegraphics[width=0.49\textwidth]{images/difference/tl_difference_2.jpg}\vspace*{0.2em}
		\includegraphics[width=0.49\textwidth]{images/difference/tl_difference_3.jpg}
		\includegraphics[width=0.49\textwidth]{images/difference/tl_difference_4.jpg}
	\caption{Sculpting a terrain model using Tangible Landscape's difference analytic.
	Blue means add sand and red means remove sand.
	}
	\label{fig:difference_sequence}
\end{center}
\end{figure}

\subsection{Applications}
Using GRASS GIS's extensive libraries for 
geospatial modeling, analysis, and simulation 
we have developed a wide range of applications for Tangible Landscape 
\cite{Petrasova2015}.
Design and planning applications include
grading, cut and fill analysis, stormwater management, erosion control, 
trail planning, viewshed analysis, and the assessment of solar potential. 
Scientific applications include
subsurface visualization, disease management, and invasive species management.
Disaster management applications include 
flood control, wildfire management, and coastal change and adaptation. 
Educational applications include
spatial training and serious gaming.

\section{Coupling experiment}
After a pilot study \cite{Harmon2016b}
we conducted an experiment to study how 
coupling digital and physical models of topography 
mediates spatial performance. 

\subsection{Methods}
In this experiment 
30 participants tried to accurately model a given study landscape 
digitally, by hand, and with Tangible Landscape. 
%
% participants
All of our participants -- either graduate students, faculty, or professionals in landscape architecture or spatial science -- 
had experience thinking spatially. 
We used spatial modeling, statistics, analysis, and simulation to quantitatively assess how participants' performance with each method differed spatially. 
We also qualitatively studied participants' modeling processes through direct observation, photographic analysis, video analysis, and semi-structured interviews. 
See Appendix 
\ref{appendix:procedure} for instructions for running the experiment
and Appendix 
\ref{appendix:guidelines} for interview guidelines. 
%
% study landscape
We used a region of Lake Raleigh Woods in Raleigh, North Carolina 
as the study landscape for this experiment. 
A real landscape was used because computer generated landscapes 
often look surreal and may lack distinct landforms and clearly defined streams. 
This study region has distinctive, 
clearly defined landforms -- a stream valley flanked by a ridge and sloping towards the lake
(see Table~\ref{table:coupling_experiment}). 
The digital elevation model for this region was derived from a 2013 airborne lidar survey 
using the regularized spline with tension interpolation method \cite{Mitasova2005}. 

\paragraph{Digital modeling}
Participants had 10 minutes to digitally model the study landscape in Rhinoceros, 
a non-uniform rational basis spline (NURBS) based 3D modeling program
designed for precise freeform curve and surface modeling \cite{Rhino}.
%\footnote{\url{https://www.rhino3d.com/}}. 
After 10 minutes of training
participants modeled the study landscape as a NURBS surface 
by vertically translating control points (Fig.~\ref{fig:rhino}). 
They started with a flat NURBS surface that was divided into a 10 x 10 grid of control points.
As a reference their model space also included a 3D representation of the study landscape as contours. 
At any point participants could rebuild the surface with a higher density of control points for finer, more nuanced control. 
This method is relatively simple and 
analogous to basic actions in sculpture -- pushing and pulling. 
%We developed and tested this method 
%as a simple, straightforward digital freeform surface modeling technique
%that could be taught quickly, yet could produce an accurate model. 
Digital modeling affords precise transformations and
dynamic modes of visualization such as 
3D orbiting, zooming, and ray traced shading. 

\begin{figure}
\begin{center}
	\includegraphics[height=108px]{images/experiments/art_rhino.jpg}
	\includegraphics[height=108px]{images/experiments/rhino.png}
	\caption{Coupling experiment - digital modeling:
	A participant digitally sculpts the study landscape in Rhinoceros
	using 3D contours as guides.}
	\label{fig:rhino}
\end{center}
\end{figure}

\paragraph{Analog modeling}
Participants had 10 minutes to sculpt the study landscape in polymer-enriched sand 
by hand or with a wooden sculpting tool. 
They were given a CNC-routed model of the study landscape as a reference. 
A lamp on the table cast shadows across the model for hillshading.
Theoretically analog modeling -- modeling by hand or with tools -- should be embodied, 
affording subconscious, kinaesthetic sensing and manipulation of form. 
By sensing form subconsciously with the body
users should have more cognitive resources for critiquing their work 
and strategizing their next moves. 

\begin{figure}
\begin{center}
	\includegraphics[width=\textwidth]{images/experiments/connie_analog_1.jpg}
	\caption{Coupling experiment - analog modeling by hand:
	A participant sculpts the study landscape by hand
	using a physical model as a reference.}
	\label{fig:analog}
\end{center}
\end{figure}

\paragraph{Projection augmented modeling}
Participants had 10 minutes to sculpt
a projection-augmented, polymer-enriched sand model
of the study landscape by hand or with a wooden sculpting tool 
(Fig.~\ref{fig:proj_aug}). 
Tangible Landscape was used to project 
an elevation map of the study landscape
with contours and a legend
onto participants' sand models as guide for sculpting. 
Participants were also given a 3D scale ruled in map units
to measure the elevation of their scale models. 
This augmented approach couples digital mapping with physical modeling.
Theoretically it should combine affordances of both -- 
enabling enriched visualization and physical sensing and manipulation -- 
to offer more feedback.
While more feedback may help users better assess and critique their performance 
so they can strategize their next moves,
too much feedback may be a cognitive overload 
resulting in distraction, frustration, and demotivation. 
Physical sensing and manipulation, however, should offload 
some of this cognitive work onto the body.

\begin{figure}[H]
\begin{center}
	\includegraphics[width=\textwidth]{images/experiments/carla_proj_aug.jpg}
	\caption{Coupling experiment - projection augmented modeling:
	A participant sculpts the study landscape using
	the projected elevation and contour maps
	as guides.}
	\label{fig:proj_aug}
\end{center}
\end{figure}

\paragraph{Data collection}
We used Tangible Landscape to scan the finished models 
built using analog hand modeling and projection augmented modeling.
The scans were captured as point clouds, interpolated 
as digital elevation models using the regularized spline with tension method,
and stored as raster maps in a GRASS GIS mapset. 
The NURBS surfaces modeled in Rhinoceros were exported as raster elevation maps,
imported into GRASS GIS, randomly resampled, 
re-interpolated using the regularized spline with tension method, 
and stored as raster maps in a GRASS GIS mapset. 
The data from Rhinoceros was randomly resampled and re-interpolated
to account for differences and irregularities in resolution, data density, and point spacing.
%caused by data conversion.

\paragraph{Data analysis}
For each set of models -- digital, analog, and augmented --
we computed cellular statistics (i.e.~per cell statistics), 
topographic and morphometric parameters, 
and simulated water flow.
% elevation
We computed 
the mean elevation 
and standard deviation of elevation
for each set
with the module \textit{r.series} \cite{r.series}.
The mean elevation is the average of each cell 
of all elevation maps in a given set of models.
%The standard deviation of elevation is the standard deviation of each cell
%of all elevation maps in a given set of models.
%
% difference 
In order to compare participants' modeling performance between sets 
we computed the difference 
between the linearly regressed reference elevation and 
the mean elevation for each set.
%
The difference between the reference and mean elevation maps should show
where the mean elevation values for each set are too low or too high. 
%
There were, however, systematic errors in the scanned models.
%
Table \ref{table:scatterplots} shows the vertical shift 
in the hand sculpted and projection augmented models 
caused by scanning and georeferencing.
%
We used linear regression 
%the linear regression of the reference and mean elevation maps
%calculated with the module \textit{r.regression.line} \cite{r.regression.line}
to vertically rescale and translate the reference elevation 
in order to account for these systematic errors
in the difference calculation,

\begin{equation}
\label{eq:regressed_difference}
\Delta = (a + b * x) - y
\end{equation}

where:

\hspace*{1em} $\Delta$ is the difference %[ft]

\hspace*{1em} $x$ is the reference elevation map %[ft]

\hspace*{1em} $y$ is the mean elevation of maps in a set %[ft]

\hspace*{1em} $a$ is the offset

\hspace*{1em} $b$ is the slope.\\

% slope
We derived the mean slope in degrees for each set 
using differential geometry
by parameterizing a quadratic function to fit mean elevation values 
in a neighborhood using least squares \cite{Wood1996} 
%through quadratic parameterization \cite{Wood1996} of the mean digital elevation model 
with the module \textit{r.param.scale} \cite{r.param.scale}.
%\footnote{\url{https://grass.osgeo.org/grass72/manuals/r.param.scale.html}}. 
%
% landforms
We computed the mean landforms for each set using geomorphons,
a pattern recognition method for landform classification 
based on the openness of the terrain
implemented as the add-on module \textit{r.geomorphon} \cite{r.geomorphon}.
%\footnote{\url{https://grass.osgeo.org/grass70/manuals/addons/r.geomorphon.html}}. 
Geomorphons works effectively across spatial scales because 
the neighborhood search size for pattern recognition 
is spatially variable -- it is set dynamically based on the visibility of the cell \cite{Jasiewicz2013}.  
Landforms can be classified as flat, peaks, ridges, shoulders, spurs, slopes, hollows, footslopes, valleys, or depressions (Fig.~\ref{fig:geomorphons}).
%
% minimum distance
We also computed the mean minimum distance between features 
such as concentrated water flow, ridges, and valleys
on the modeled landscapes and the reference landscape.

\begin{table}
\tbl{Bivariate scatterplots of elevation values}{
\ra{1.3}
\begin{tabular}{m{0.05\textwidth} m{0.3\textwidth} m{0.3\textwidth} m{0.3\textwidth}}
\toprule
& \multicolumn{1}{c}{Digital} & \multicolumn{1}{c}{Analog}  & \multicolumn{1}{c}{Augmented}\\
\midrule \\
Mean & 
\includegraphics[width=0.3\textwidth]{images/bivariate_scatterplots/dem_1.png} &
\includegraphics[width=0.3\textwidth]{images/bivariate_scatterplots/dem_2.png} &
\includegraphics[width=0.3\textwidth]{images/bivariate_scatterplots/dem_3.png}\\
& \multicolumn{1}{c}{Reference} & \multicolumn{1}{c}{Reference} & \multicolumn{1}{c}{Reference} \\
\\
\bottomrule
\end{tabular}}
\label{table:scatterplots} 
\end{table}

% landform legend
\begin{figure}
\begin{center}
		\includegraphics[width=\textwidth]{images/geomorphons_legend.png}
	\caption{Landforms identified by \textit{r.geomorphon}. 
		Source: \cite{r.geomorphon}.}
	\label{fig:geomorphons}
\end{center}
\end{figure}

\subsection{Results}
%
Participants digitally modeled so approximately and abstractly 
with Rhinoceros
that they only hinted at landforms. % at the morphology.
%
When they sculpted by hand
their models tended to be descriptive -- 
differing substantially from the reference, but
accurately representing most of the landforms. 
%
Their performance improved 
when they sculpted projection-augmented models --
the resulting models
fit the reference better, 
had more defined topography, 
and accurately represented most of the landforms.
%
Table \ref{table:scatterplots} shows systematic errors
in the hand sculpted and projection-augmented models;
these models are vertically shifted due to scanning
and have low values along the borders
caused by slumping sand. 
While we used linear regression 
to vertically shift and rescale the difference in elevation, 
we did not mitigate the systematic errors
along the borders. 
%
Table \ref{table:coupling_experiment} shows 3D maps of cellular statistics 
and geospatial analyses for this experiment.

\begin{table}
\tbl{Coupling experiment: maps of per-cell statistics and geospatial analyses draped over 3D topography}{
\ra{1.3}
\begin{tabular}{m{0.19\textwidth} m{0.19\textwidth} m{0.19\textwidth} m{0.19\textwidth} m{0.19\textwidth}}
\toprule
& \multicolumn{1}{c}{Reference} & \multicolumn{1}{c}{Digital} & \multicolumn{1}{c}{Analog}  & \multicolumn{1}{c}{Augmented}\\
\midrule
%
Mean elevation (ft) \par \vspace{0.5em} \includegraphics[width=0.19\textwidth]{images/legends/elevation_legend_1.pdf} & 
\includegraphics[width=0.19\textwidth]{images/render_3d/dem_1.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/mean_dem_1.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/mean_dem_2.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/mean_dem_3.png}\\
%
Stdev.~of elevations \par \vspace{0.5em} \includegraphics[width=0.19\textwidth]{images/legends/stdev_legend.pdf} & 
\includegraphics[width=0.19\textwidth]{images/render_3d/dem_difference_1.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/stdev_dem_1.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/stdev_dem_2.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/stdev_dem_3.png}\\
%
Stdev.~of difference \par \vspace{0.5em} \includegraphics[width=0.19\textwidth]{images/legends/stdev_diff_legend.pdf} & 
\includegraphics[width=0.19\textwidth]{images/render_3d/dem_difference_1.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/stdev_regression_difference_series_1.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/stdev_regression_difference_series_2.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/stdev_regression_difference_series_3.png}\\
%
Mean difference (ft) \par \vspace{0.5em} \includegraphics[width=0.19\textwidth]{images/legends/diff_legend_1.pdf} & 
\includegraphics[width=0.19\textwidth]{images/render_3d/dem_difference_1.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/mean_dem_regression_difference_1.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/mean_dem_regression_difference_2.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/mean_dem_regression_difference_3.png}\\
%
Mean slope (\%) \par \vspace{0.5em} \includegraphics[width=0.19\textwidth]{images/legends/slope_legend_1.pdf} & 
\includegraphics[width=0.19\textwidth]{images/render_3d/slope_1.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/mean_slope_1.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/mean_slope_2.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/mean_slope_3.png}\\
%
Mean landforms \par \vspace{0.5em} \includegraphics[width=0.19\textwidth]{images/legends/forms_legend.pdf} & 
\includegraphics[width=0.19\textwidth]{images/render_3d/forms_1.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/mean_forms_1.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/mean_forms_2.png} &
\includegraphics[width=0.19\textwidth]{images/render_3d/mean_forms_3.png}\\
%
\bottomrule
\end{tabular}}
\label{table:coupling_experiment} 
\end{table}

\begin{table}
\tbl{Coupling experiment: percent cells}{
\ra{1.3}
\begin{tabular}{c <{\hspace{1em}} c <{\hspace{1em}} c <{\hspace{3em}} c}
\toprule
Method & Concentrated flow & Ridges & Valleys \\
\midrule
Reference & 0.89 & 2.10 & 2.90\\
Digital & 1.12 & 0.69 & 0.56\\
Hand & 0.80 & 4.00 & 1.66\\
Augmented & 0.77 & 4.13 & 1.48\\
\bottomrule
\end{tabular}}
\label{table:percent_cells} 
\end{table}

\begin{table}
\tbl{Mean minimum distance (ft) of features from reference features}{
\ra{1.3}
\begin{tabular}{c <{\hspace{0.5em}} c <{\hspace{1em}} c <{\hspace{3.5em}} c}
\toprule
Method & Concentrated flow & Ridges & Valleys \\
\midrule
Digital & 12916 & 110419 & 98806\\
Hand & 10162 & 24005 & 676450\\
Augmented & 7121 & 19599 & 31401\\
\bottomrule
\end{tabular}}
\label{table:distance} 
\end{table}

\paragraph{Mean elevation}
The mean digitally modeled elevation is a highly abstract massing model
lacking any detail. 
% 
The mean hand sculpted elevation 
is less abstract, more detailed, and more descriptive.
%
The mean projection-augmented elevation 
is even more detailed and defined. 

\paragraph{Standard deviation of elevations}
The standard deviation of elevations represents the set's consistency.
%
When digitally modeling 
participants treated the lake very consistently, but 
varied substantially in their treatment of the highpoint.
%
We observed participants 
using similar digital modeling strategies 
in a relatively linear fashion -- 
they typically began by modeling the profiles in the elevation views,
then pulled up the relative high points, 
and finally pushed down the relative low points. 
 %
They were very inconsistent 
when sculpting by hand,
varying greatly in their treatment 
everywhere except the valley and the lakeside.
%
We observed participants using 
a wide range of different modeling strategies
and techniques
when sculpting by hand. 
%
With projection-augmented modeling 
participants varied in their handling of relative high points, 
but were relatively consistent otherwise. 

\paragraph{Standard deviation of differences}
The standard deviation of differences shows 
how consistently the models fit the reference. 
%
The digitally modeled landscapes deviated the most from the reference
with substantial errors along the ridge and valley. 
%
The hand sculpted landscapes 
more consistently fit the reference
and
the projection-augmented landscapes 
most consistently fit. 

\paragraph{Mean elevation difference}
The difference between the linearly regressed reference and the mean elevation
shows where participants 
differed from the reference on average, i.e.~where they 
needed to add (blue) or remove (red) volume to match the reference. 
%
The digitally modeled landscapes 
had low values along the ridge,
high values on the slopes around the ridge,
and high values along the valley
with no channel modeled.
% 
The hand sculpted landscapes 
had high values on most slopes,
accurate values along the ridge, 
and low values along the borders.
%
The projection-augmented landscapes 
had accurate values along the ridge,
accurate values on some slopes, 
low values on others, 
and low values along the borders.

\paragraph{Mean slope}
The reference landscape had 
much steeper slopes and thus more 
defined features
than any of the models.
%
The digitally modeled landscapes
were dominated by gentle slopes
with steep slopes on only one side of the ridge.
These models
least accurately represented the slope and curvature.
% 
The hand sculpted landscapes 
had steeper slopes
that began to define key morphological features 
like the ridge and valley.
%
The projection-augmented landscapes 
had steep slopes along the ridge
creating a well defined ridge-line. 

\paragraph{Mean landforms}
The digitally modeled landscapes
represented the peak of the ridge
and hinted at the valley, 
but missed all of the other landforms.
% 
Both the hand sculpted and projection-augmented landscapes 
accurately represented the ridge and its peak.
They also represented most of the valley,
but did not accurately capture its shape. 
They had anomalous ridges and peaks 
near the high point
caused by slumping sand along the border.

\paragraph{Minimum distance}
We used
the mean minimum distance between cells
with water flow, ridges, and valleys
on the models and the reference
as a measure of positional accuracy. 
%
The projection-augmented landscapes 
were the most accurate
with the lowest mean minimum distance for cells with
concentrated water flow, ridges, and valleys
(see Tables \ref{table:percent_cells} \& \ref{table:distance}). 

\paragraph{Observations}
% digital
We observed participants using similar strategies in a linear process 
when digitally modeling. 
Since the reference data -- the 3D contour curves -- 
clearly represented profiles, 
participants typically began by modeling the borders %-- each profile -- 
of the landscape.
Then they began to pull up relative high points 
to build a rough massing model of the topography.
Finally they began to pull down relative low points to 
steepen slopes and form valleys.
% analog and augmented
We observed that participants 
worked in a more freeform manner 
when hand sculpting -- switching freely between
adding, removing, pressing, pushing, pulling, or smoothing
sand.

\paragraph{Interviews}
One participant said that she felt anxious when digitally modeling,
but felt calmer and more relaxed when hand sculpting sand. 
%
She found hand sculpting to be more intuitive, saying that
while digital modeling had `a long learning curve,' 
%she could read the sand model `like braille\ldots 
%I could feel the shape with my fingers.'
she could feel the shape of the sand model with her fingers.
%
%projection-augmented modeling 
Another participant found that 
with projection-augmented modeling 
he was able to effectively combine 
the affordances of hand sculpture 
with the extra layer of data. 
%
He described an iterative strategy of additive modeling
in which the projected `contours were just a guide' --  
`My general strategy was additive. 
I felt with my hands to try to match the contours. 
If I saw concavity in the contours 
then I felt the sand and sculpted that concavity.
Finding the relative height, however, was challenging -- it was subtle.'

\section{Difference experiment}
We conducted an experiment to study 
how the difference analytic mediates spatial performance 
when using a tangible interface for GIS.

\begin{figure}
\begin{center}
	\includegraphics[width=\textwidth]{images/experiments/connie_difference_2.jpg}
	\caption{Difference experiment: 
	A participant sculpts the study landscape using Tangible Landscape's difference
	analytic, which shows where to add sand (blue) and remove sand (red).}
	\label{fig:diff}
\end{center}
\end{figure}

\subsection{Methods}
%
\paragraph{Difference analytic}
The same 30 participants were asked to use 
Tangible Landscape's difference analytic to model 
a different region of Lake Raleigh Woods
with a large central ridge 
flanked by valleys 
and a smaller, secondary ridge.
Participants had 10 minutes to model this region
in polymer-enriched sand using Tangible Landscape 
with the difference analytic (Fig.~\ref{fig:diff}). 
The difference between the reference elevation 
and the participant's modeled elevation %the scanned elevation map
was computed in near real-time and projected onto the sand 
as an interactive guide.
The linear regression of the reference and scanned elevation maps was used
to correct shifts in scanning and georeferencing. 
The difference showed where sand needs to added (blue) or removed (red) 
in order to match the reference landscape (Fig.~\ref{fig:difference_sequence}). 
While this feedback should show participants what to do next, 
it may provide too much data or be too challenging to rapidly parse. 

\begin{minted}[fontsize=\small]{python}
def run_difference(real_elev, scanned_elev, env, **kwargs):
	regression_params = gscript.parse_command('r.regression.line', 
		flags='g',
		mapx=scanned_elev,
		mapy=real_elev,
		env=env)
	gscript.mapcalc('{regression} = {a} + {b} * {before}'.format(
		a=regression_params['a'],
		b=regression_params['b'],
		before=scanned_elev,
		regression='regression'),
		env=env)
	gscript.mapcalc('{difference} = {regression} - {after}'.format(
		regression='regression',
		after=real_elev, difference='diff'),
		env=env)
	gscript.write_command('r.colors', 
		map='diff',
		rules='-',
		stdin="-100 black\n-20 red\n0 white\n20 blue\n100 black",
		env=env)
\end{minted}

\paragraph{Data collection and analysis}
The final scan of each model was stored in a mapset for analysis. 
We used cellular statistics, the difference in elevation, 
topographic parameters, and morphometric parameters
to compare the reference elevation and the set of modeled elevations. 
We computed 
the mean elevation,
the standard deviation of elevations, 
and the standard deviation of difference for the set.
To find the standard deviation of differences 
we first computed the difference between the reference elevation and each elevation 
and then used cellular statistics to find the standard deviation of these differences.
We also computed the difference between the 
reference elevation and the mean elevation for the set. 
The reference elevation used in the difference calculation was rescaled and shifted based on the linear regression of the reference and mean elevation.
We computed the slope and landforms of the mean elevation. 

We also filmed each session, 
observed and took notes on participants' modeling processes, 
and interviewed select participants.
% 

\subsection{Results}
Participants tended to perform well with the difference analytic 
-- modeling simplified, but relatively accurate approximations of the landscape.
Since these models were sculpted in sand
their edges tend to slump.
This caused artifacts in the analysis like
low elevation values and steep slopes
along the borders. 
%
Table \ref{table:difference_stats} shows maps of cellular statistics for this experiment.
%
%  mean
The mean elevation for this set of models
has the approximate shape of the reference elevation, 
but is much simpler, lacking many details. 
% stdev
%The standard deviation of elevations represents the set's consistency.
The standard deviation of elevations shows that participants 
consistently modeled the low point at the base of the secondary ridge
in the same way, 
but modeled the primary ridge in different ways. 
% stdev diff
The standard deviation of difference shows 
%how much the set deviated from the best fit with the reference. 
how consistently the models fit the reference. 
Overall participants performed well -- there was little deviation from the best fit. 
Participants tended to perform poorly near the edges of models, especially in the corners.
They also performed poorly with the valleys and the low point by the secondary ridge.

Table \ref{table:difference_experiment} shows geospatial analyses for this experiment.
%
The mean elevation difference shows that participants tended to add
too little to the edges of the model,
too much to primary ridge,
and too much to the slope of the secondary ridge. 
%
% slope
The mean slope shows that participants tended to model 
overly steep slopes for the primary ridge -- exaggerating its form --
but tended not model steep enough slopes for the secondary ridge. 
%
% landforms
The mean landforms show that participants tended to 
clearly capture the central ridge and its spurs,
suggest the secondary ridge, 
and miss the valleys (see Table \ref{table:difference_percent_cells}). 
The secondary ridge has an inchoate form 
with small clusters of ridge cells along a spur.
Hollows -- transitions between slopes, footslopes, and valleys -- 
on the mean landform map hint at valleys in the right locations.
%but lack definition and steepness.



\paragraph{Interviews and observations}
% understanding volume
To successfully use the difference analytic 
participants had to think about topography as volume.
They had to either add or excavate sand to make the models match. 
They described the process of modeling with the difference analytic
as continual 'rebuilding to make it match.'
% iterative process
They described an iterative process of 
continual refinement based on critical analysis 
-- similar to Sch{\"o}n's reflection-in-action --
but enhanced by computational feedback 
explaining that 
`because Tangible Landscape gives immediate results it encourages an iterative process.' 

% conclusions
The difference analytic is intuitive -- 
participants were able to learn how to use it effectively without training, 
producing good, albeit exaggerated approximations of the landscape. 
%
Their models had key morphometric characteristics -- 
the primary ridge, its spurs, the low point, 
hints of the secondary ridge and some valleys -- 
but these characteristics were either exaggerated or under-exaggerated.

\begin{table}
\tbl{Difference experiment: maps of per-cell statistics draped over a 3D rendering of the topography}{
\ra{1.3}
\begin{tabular}{m{0.24\textwidth} m{0.24\textwidth} m{0.24\textwidth} m{0.24\textwidth}}
\toprule
\multicolumn{1}{c}{Reference elevation} & \multicolumn{1}{c}{Mean elevation} & \multicolumn{1}{c}{Stdev.~ of elevations}  & \multicolumn{1}{c}{Stdev.~ of differences}\\
\midrule
%
\includegraphics[width=0.24\textwidth]{images/render_3d/dem_4.png} &
\includegraphics[width=0.24\textwidth]{images/render_3d/mean_dem_4.png} &
\includegraphics[width=0.24\textwidth]{images/render_3d/stdev_dem_4.png} &
\includegraphics[width=0.24\textwidth]{images/render_3d/stdev_regression_difference_series_4.png}\\
%
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/elevation_legend_4.pdf}} &
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/elevation_legend_4.pdf}} &
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/stdev_legend.pdf}} &
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/stdev_diff_legend.pdf}}\\
%
\bottomrule
\end{tabular}}
\label{table:difference_stats} 
%
\vspace*{1.5em}
%
\tbl{Difference experiment: maps of geospatial analyses draped over a 3D rendering of the topography}{
\ra{1.3}
\begin{tabular}{m{0.1\textwidth} m{0.22\textwidth} m{0.22\textwidth} m{0.22\textwidth} m{0.22\textwidth}}
\toprule
& \multicolumn{1}{c}{Elevation} & \multicolumn{1}{c}{Elevation difference} & \multicolumn{1}{c}{Slope}  & \multicolumn{1}{c}{Landform}\\
\midrule
%
Reference & 
\includegraphics[width=0.22\textwidth]{images/render_3d/dem_4.png} &
\includegraphics[width=0.22\textwidth]{images/render_3d/dem_difference_4.png} &
\includegraphics[width=0.22\textwidth]{images/render_3d/slope_4.png} &
\includegraphics[width=0.22\textwidth]{images/render_3d/forms_4.png}\\
%
Mean & 
\includegraphics[width=0.22\textwidth]{images/render_3d/mean_dem_4.png} &
\includegraphics[width=0.22\textwidth]{images/render_3d/mean_dem_difference_4.png} &
\includegraphics[width=0.22\textwidth]{images/render_3d/mean_slope_4.png} &
\includegraphics[width=0.22\textwidth]{images/render_3d/mean_forms_4.png}\\
%
&
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/elevation_legend_4.pdf}} &
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/diff_legend_4.pdf}} &
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/slope_legend_1.pdf}} &
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/forms_legend.pdf}}\\
%
\bottomrule
\end{tabular}}
\label{table:difference_experiment} 
%
\vspace*{1.5em}
%
\tbl{Difference experiment: percent cells}{
\ra{1.3}
\begin{tabular}{rrcccccccc}\toprule
Method && \multicolumn{2}{c}{Concentrated flow} & \phantom{abc}& \multicolumn{2}{c}{Ridges} &
\phantom{abc} & \multicolumn{2}{c}{Valleys}\\
\cmidrule{3-4} \cmidrule{6-7} \cmidrule{9-10}
&& Reference & Mean && Reference & Mean && Reference & Mean\\ \midrule
Difference && 1.07 & 0.73 && 4.27 & 3.46 && 2.96 & 0.22\\
\bottomrule
\end{tabular}}
\label{table:difference_percent_cells} 
%
%\vspace*{1.5em}
%%
%\tbl{Mean minimum distance (ft) of features from reference features}{
%\ra{1.3}
%\begin{tabular}{c <{\hspace{1em}} c <{\hspace{1.5em}} c <{\hspace{4em}} c}
%\toprule
%Method & Concentrated flow & Ridges & Valleys \\
%\midrule
%Difference & 25073 & 35656 & 114378\\
%\bottomrule
%\end{tabular}}
%\label{table:difference_distance} 
\end{table}

\section{Water flow experiment}
After a pilot study \cite{Harmon2016}
we conducted an experiment to study 
how water flow analytics 
in a tangible interface for GIS
mediate spatial performance.

\subsection{Methods}
\paragraph{Water flow analytic}
The same 30 participants were asked to model water flow 
across another region of Lake Raleigh Woods
using Tangible Landscape with the water flow analytic.
This region has a central ridge 
flanked by a large stream on one side 
and a small stream on the other.  
A third, smaller stream bisects the ridge.
Participants had 10 minutes to model water flow across this region
by sculpting polymer-enriched sand using Tangible Landscape 
with the water flow analytic. 
They sculpted sand models of the topography
to direct the simulated flow of water.  
Water flow was simulated in near real-time 
as a diffusive wave approximation of shallow water flow.
The module \textit{r.sim.water} \cite{r.sim.water}
uses a path sampling technique to solve the shallow water flow continuity equation \cite{Mitasova2004}.
Participants could switch between the precomputed reference water flow 
-- i.e.~their target -- 
and the water flow over their scanned model. 

\begin{figure}
\begin{center}
	\includegraphics[width=0.9\textwidth]{images/experiments/tl_water.jpg}
	\caption{Water flow experiment: 
	A participant sculpts the study landscape using Tangible Landscape's water flow
	analytic.}
	\label{fig:flow_sequence}
\end{center}
\end{figure}

\paragraph{Data collection and analysis}
The final scan of each model was stored in a mapset for analysis. 
We used cellular statistics, simulated water flow, and the difference in simulated water depth 
to compare water flow across the study landscape and the set of models.
We computed the mean elevation,
the standard deviation of elevations, 
and the standard deviation of difference for the set.
Then we simulated water flow across the mean elevation for the set of models
and computed the difference between the reference and mean water flow. 

\subsection{Results}
Participants tended to perform well with the water flow analytic 
-- approximately modeling all three streams.  
%
Table \ref{table:water_flow_stats} shows maps of cellular statistics for this experiment.
%  mean
The mean elevation for this set of models
has under-exaggerated valleys in the right places, but exaggerated ridges. 
The mean elevation has 19.08\% less valleys than the reference, but
68.28\% more ridges (see Table \ref{table:water_flow_percent_cells}). 
% stdev
The standard deviation of elevations shows that participants 
consistently modeled the streams, but
varied greatly in their treatment of the primary ridge. 
% stdev diff
The standard deviation of difference shows that participants 
performed well 
with the greatest deviation from the reference
in the corners and along the edges. 
Again this is to be expected 
as sand slumps along the borders. 

Table \ref{table:water_flow_experiment} shows geospatial analyses for this experiment.
% water depth
The mean water depth map shows all three streams, 
simplified, but in the right locations. 
The simplified stream channels lack micro-topography
and thus the streams lack details. 
Table \ref{table:water_flow_percent_cells} shows that 
there was substantial concentrated flow (water depth $>=0.05$ ft) 
in the streams, albeit 22\% less than in the reference.
%
This is to be expected 
since 
water flow over the sculpted models was only computed over the model region, 
while 
the reference water flow 
was computed over a larger region 
with the entire contributing watershed 
in order to produce an accurate representation 
of water flow across the study landscape. 
%
% depth difference
The water depth difference map shows
where water should be added (red) or removed (blue) 
to match the reference
-- i.e.~where water should flow versus where it was modeled. 
%
The mean water flow tightly fit the reference, 
following similar, albeit simplified routes.

\begin{table}
\tbl{Water flow experiment: maps of per-cell statistics draped over a 3D rendering of the topography}{
\ra{1.3}
\begin{tabular}{m{0.24\textwidth} m{0.24\textwidth} m{0.24\textwidth} m{0.24\textwidth}}
\toprule
\multicolumn{1}{c}{Reference elevation} & \multicolumn{1}{c}{Mean elevation} & \multicolumn{1}{c}{Stdev.~ of elevations} & \multicolumn{1}{c}{Stdev.~ of differences}\\
\midrule
\includegraphics[width=0.24\textwidth]{images/render_3d/dem_5.png} &
\includegraphics[width=0.24\textwidth]{images/render_3d/mean_dem_5.png} &
\includegraphics[width=0.24\textwidth]{images/render_3d/stdev_dem_5.png} &
\includegraphics[width=0.24\textwidth]{images/render_3d/stdev_regression_difference_series_5.png}\\
%
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/elevation_legend_5.pdf}} &
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/elevation_legend_5.pdf}} &
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/stdev_legend.pdf}} &
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/stdev_diff_legend.pdf}}\\
%
\bottomrule
\end{tabular}}
\label{table:water_flow_stats} 
%
\vspace*{1.5em}
%
\tbl{Water flow experiment: maps of geospatial analyses draped over a 3D rendering of the topography}{
\ra{1.3}
\begin{tabular}{m{0.1\textwidth} m{0.3\textwidth} m{0.3\textwidth} m{0.3\textwidth}}
\toprule
& \multicolumn{1}{c}{Elevation} & \multicolumn{1}{c}{Water depth} & \multicolumn{1}{c}{Depth difference}\\
\midrule
%
Reference & 
\includegraphics[width=0.3\textwidth]{images/render_3d/dem_5.png} &
\includegraphics[width=0.3\textwidth]{images/render_3d/depth_5.png} &
\includegraphics[width=0.3\textwidth]{images/render_3d/dem_difference_5.png}\\
%
Mean & 
\includegraphics[width=0.3\textwidth]{images/render_3d/mean_dem_5.png} &
\includegraphics[width=0.3\textwidth]{images/render_3d/mean_depth_5.png} &
\includegraphics[width=0.3\textwidth]{images/render_3d/mean_depth_difference_5.png}\\
%
& 
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/elevation_legend_5.pdf}} &
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/depth_legend.pdf}} &
\multicolumn{1}{c}{\includegraphics[width=0.22\textwidth]{images/legends/depth_diff_legend.pdf}}\\
%
\bottomrule
\end{tabular}}
\label{table:water_flow_experiment} 
%
\vspace*{1.5em}
%
\tbl{Water flow experiment: percent cells}{
\ra{1.3}
\begin{tabular}{rrcccccccc}\toprule
method && \multicolumn{2}{c}{concentrated flow} & \phantom{abc}& \multicolumn{2}{c}{ridges} &
\phantom{abc} & \multicolumn{2}{c}{valleys}\\
\cmidrule{3-4} \cmidrule{6-7} \cmidrule{9-10}
&& reference & mean && reference & mean && reference & mean\\ \midrule
water flow && 2.55 & 1.99 && 1.18 & 3.72 && 4.77 & 3.86\\
\bottomrule
\end{tabular}}
\label{table:water_flow_percent_cells} 
%%
%\vspace*{1.5em}
%%
%\tbl{Mean minimum distance (ft) of features from reference features}{
%\ra{1.3}
%\begin{tabular}{c <{\hspace{1em}} c <{\hspace{1.5em}} c <{\hspace{4em}} c}
%\toprule
%Method & Concentrated flow & Ridges & Valleys \\
%\midrule
%Water flow & 28321 & 37918 & 26166\\
%\bottomrule
%\end{tabular}}
%\label{table:flow_distance} 
\end{table}


% observations
With the water flow analytic
participants focused on accurately modeling the streams, 
rather than the general shape of the topography. 
As a result the primary ridge was inconsistently modeled and over-exaggerated,
while the streams were consistently modeled,
had high volumes of continuous water flow, 
and flowed along the correct routes.

% understanding water flow
This experiment required abstract spatial thinking linking form and process. 
Because water flow is controlled by the shape and gradient of the topography
participants had to sculpt topographic form to drive water flow. 
% interviews
This modeling process, however, helped them understand topography better 
because `seeing the flow takes away the mystery of topography.' 
%
We observed participants using an iterative modeling process 
with the water flow analytic -- 
they 
\begin{enumerate*}[label=\alph*),font=\itshape]
\item sculpted the topography, 
\item observed how the water flow simulation changed, 
\item critiqued their water flow and topography, 
\item and continued to sculpt.
\end{enumerate*}
%
Using the water flow analytic with this trial-and-error process
participants were able to generate hypotheses, test hypotheses, and draw inferences 
about the way that water flows over topography. 
%
%One participant described this trail-and-error process as tinkering --
%`Tangible Landscape let me tinker. 
%I could rapidly create, making new iterations. 
%I could try something, see and feel it -- directly experience it --
%and try again. Reinvent it.'
%`Tangible Landscape lowers the stakes so that you're not too invested.
%You're ready to fail. So you can intuitively explore, 
%while reflecting on what you've done,
%what you're doing.'

%Participants suggested that the water flow analytic might be 
%most useful for refining stream channels 
%after modeling the topography with the difference analytic. 
%% `More useful after modeling with the difference.' 
%% i.e.~Build mass with difference, then refine with water flow
%% a useful way of thinking about topography, but harder to model with


%\section{Case studies}
%
%We hosted a scientific gaming workshop using Tangible Landscape 
%as part of North Carolina State University Library's Coffee \& Viz series. 
%In this workshop participants 
%explored complex environmental problems 
%by playing serious, analytical games
%with challenging objectives, rules, and scores. 
%In the games
%participants used simple tangible interactions 
%to computationally steer simulations -- 
%to drive simulated environmental processes. 
%
%In one game participants managed 
%the spread of termites across a city by treating city blocks. 
%After watching the simulated spread of termites across the city, 
%participants placed preventative treatments to try to contain the invasion. 
%To treat a city block they placed wooden cubes 
%representing preventive treatments on the game board 
%leveraging basic motor skills from childhood play.
%After they treated 10 blocks
%the stochastic simulation was rerun
%so participants could see how well they contained the invasion. 
%(Fig.~\ref{fig:termite_game}).
%
%In the other game participants tried to save houses 
%from coastal flooding by building coastal defenses. 
%Given a small handful of polymer-enriched sand 
%-- their budget -- 
%they sculpted new dunes as flood defenses
%again leveraging motor skills from childhood play.
%The foredune was then breached at a random location 
%and simulated storm surge was run, flooding any vulnerable houses. 
%(Fig.~\ref{fig:coastal_game}). 
%
%At another station participants could also playfully interact 
%with a water flow simulation
%in an unstructured way. 
%Several participants could simultaneously sculpt 
%a sand model of a landscape and see how they changed
%simulated water flow % (Fig.~\ref{fig:tl_flow}) 
%learning how shape affects process through unstructured play.
%They used Tangible Landscape in new, unexpected ways --
%cupping their hands, for example, to fill their palms with projected water.
%
%We observed that participants were able to naturally 
%interact with the statistical model of ecological invasion,
%the flood simulation, and the water flow simulation. 
%Because the interactions were so simple % yet afforded so much 
%-- just moving wooden blocks or sculpting sand --
%they were able to continually reconfigure the model,
%dynamically exploring the behavior 
%of multidimensional environmental processes
%unfolding in time and space. 
%By playing several rounds participants were able to 
%iteratively observe the simulated environmental process, 
%generate hypotheses about its behavior, 
%test how interventions affected its behavior, 
%and draw inferences. 
%
%\begin{figure}
%\begin{center}
%		\includegraphics[width=0.3\textwidth]{images/termite_game_1.jpg}
%		\includegraphics[width=0.3\textwidth]{images/termite_game_2.jpg}
%		\includegraphics[width=0.3\textwidth]{images/termite_game_3.jpg}
%	\caption{Managing the simulated spread of termites through a city with Tangible Landscape}
%	\label{fig:termite_game}
%\end{center}
%\end{figure}
%
%\begin{figure}
%\begin{center}
%		\includegraphics[width=0.3\textwidth]{images/tl_coastal_1s.png}
%		\includegraphics[width=0.3\textwidth]{images/tl_coastal_3s.png}
%		\includegraphics[width=0.3\textwidth]{images/tl_coastal_4s.png}
%	\caption{Testing coastal flood defences with Tangible Landscape}
%	\label{fig:coastal_game}
%\end{center}
%\end{figure}

\section{Discussion}
% coupling
The results of the coupling experiment show that 
coupling a physical and digital model of topography 
can improve spatial performance. 
%
The projection-augmented models tended
to more accurately fit the reference, 
accurately represent landforms, 
have more defined topography
than the other models. 
%
The hand sculpted models tended
to less accurately fit the reference, but
were still very descriptive 
-- accurately representing the landforms. 
%
The digitally sculpted models tended
to be inaccurate and highly approximate,
only abstractly representing the reference
and hinting at landforms. 
%
Users' enhanced performance with projection augmented modeling 
demonstrates that they can successfully 
combine the physical and computational affordances 
of analog and digital modeling. 

Since we used a NURBS based 3D modeling program 
for digital sculpting
the results were constrained to smooth, circular shapes %isotropic
formed by splines.
%
In the pilot study we also tested Vue's terrain editor,
a triangulated irregular network based 3D modeling program 
for intuitive terrain sculpting \cite{Vue},
and determinted that the results were 
less smooth with sharper transitions and
had obvious triangular artifacts.
%were constrained to composite shapes
%composed of different sized triangles.
The triangulated structure caused
exaggerated slopes and discontinuous water flow. 
%
The models sculpted in polymer-enriched sand 
were much less constrained 
because the medium has a very fine, uniform grain size,
a good balance of plasticity and adhesiveness,
and thus can be sculpted into a smooth, continuous shape
with fine details.

% difference
The results of the difference experiment show that 
the difference analytic 
enabled an iterative modeling process
successfully combining the affordances of physical modeling
with near real-time computational feedback. 
%
Participants tended to perform well without training 
successfully managing to %rapidly parse and 
understand the analytic
and use it to adaptively sculpt.
%
This suggests that they were able to offload the cognitive work 
of manipulation onto their bodies, while cognitively 
parsing a rapidly changing, graphical representation of the difference in volume.

We observed, however, that some participants had trouble understanding
the color table for the difference analytic. 
We used a relative color table 
that assigned colors based on percentage of value.
The color table rescaled every scan 
so participants had a hard time quantifying their overall performance.
This caused participants to make exaggerated changes in places
where only minor adjustments were needed.
%
After the experiment we tested an absolute color table
with colors assigned to specific values.
The absolute color table helped -- it was much easier 
to observe gradual, incremental progress throughout the modeling process.

% water flow
The results of the water flow experiment show 
that the water flow simulation helped participants 
understand the relationship between form and process.
We observed participants using an iterative process
to adaptively sculpt based on the simulated water flow. 
%By iteratively sculpting the topography to direct water flow
Through this trial and error process 
participants learned how
topographic form controls the flow of water.
%
Given that they accurately represented the streams without training
they may have been able to offload 
some of the cognitive work of sensing and manipulating 
3D form onto their bodies so that 
they could focus on the water flow. 

% metacognition
Tangible Landscape enabled users 
to model in an iterative process informed by spatial analytics. % computational analytics
%
We theorize that users offloaded the cognitive work 
of sensing and manipulating 3D form onto their bodies,
successfully parsed the projected graphics,
and metacognitively adapted their modeling strategy.
%
Given the accuracy of their models 
participants did not suffer from too great a cognitive overload 
-- they must have been able to offload enough cognitive work onto their bodies
to handle the analytic feedback, critique their performance, and re-strategize.

The experiments helped us to refine the design of Tangible Landscape. 
%
We learned how users performed with different modes of analytic feedback, 
gained insight about their experiences and needs,
realized the importance of color tables, 
and reaffirmed the need for speed -- the importance of fast feedback. 
%
This informed the development of the next generation of Tangible Landscape 
and led to the redesign of the difference analytic. 

After the experiments
we developed the \nth{3} generation Tangible Landscape system
using 
the OpenKinect project for drivers,
the Point Cloud Library for point cloud processing, 
and OpenCV for computer vision. 
%
This dramatically increased the speed of the system
%reducing lag to approximately 2 seconds
tripling the rate of feedback.
so that there is only approximately 2 seconds of lag. 
%
Now that the analytics are closer to real-time to
users should perform even better than they did in the experiments.
%
As a test a member of our research team 
performed the task for the difference experiment 
using the new generation of Tangible Landscape
and produced a very accurate model \cite{ncsu_geoforall_2016}. 

% Embed video in online edition if possible / Include video in supplemental material

\subsection{Open science}
As a work of open science we invite readers to
replicate or build upon this experiment by 
using or adapting our tangible interface, experimental methodology, code, and data. 
The python scripts for data processing and analysis used in this experiment 
are available on GitHub at 
\url{https://github.com/baharmon/tangible_topography}
released under the GNU General Public License (GPL). 
See Appendix \ref{appendix:procedure}
and the documentation in the GitHub repository 
for detailed instructions for replicating this experiment. 
The data used in this experiment 
and the results -- 
including data, renderings, photographs, and interview notes --
are available on the Open Science Framework 
at \url{https://osf.io/82gst/} under the Creative Commons Zero license.
While the rest of the software used in this research is free and open source, 
Rhinoceros is proprietary software. 
Open source 3D modeling programs like 
Blender, however,
could be substituted for Rhinoceros. 

To build your own Tangible Landscape
refer to Appendix \ref{appendix:howto},
visit the project website at \url{http://tangible-landscape.github.io/}, 
see the documentation in the GitHub repository 
including the Wiki at \url{https://github.com/tangible-landscape/grass-tangible-landscape/wiki},
and refer to the book Tangible Modeling with Open Source GIS \cite{Petrasova2015}.
GRASS GIS is available at
\url{https://grass.osgeo.org/} 
under the GPL. 
Tangible Landscape's components are available at
\url{https://github.com/tangible-landscape}
under the GPL. 
%\url{https://github.com/ncsu-osgeorel/grass-tangible-landscape} and 
%\url{https://github.com/tangible-landscape/r.in.kinect}

\section{Future work}
%
\subsection{Future cognitive studies}
%
This study focused on spatial performance
using geospatial analyses to assess modeling results. 
%
It did not quantitively address cognitive, affective, motivational, or metacognitive processes. 
%
Future research in embodied spatial cognition with tangible interfaces 
should quantitively study these processes using methods like 
eye tracking and biometric sensing.  
%
Future research should also study spatiotemporal performance
using time series analysis to assess participants' modeling processes.
%
Suitable methods for spatiotemporal analysis and visualization include 
space-time cubes, 3D raster statistics and map algebra, 
vector flow fields, contour evolution, and animation.

\subsection{Robotic fabrication and autonomous construction}
%
Emerging technologies are enabling the ever more close coupling 
of the physical and the digital, 
bridging real and virtual geographies. 
%
With advances in sensor networking like the internet of things and pervasive sensing 
physical things and environmental processes
can be digitally tracked, sensed, and analyzed  
-- giving the physical a digital presence \cite{Ratti2009,Resch2011} . 
%
With advances in sensing technologies
3D forms can be digitized at scales ranging from millimeters to the entire planet.
%
Data can be digitally fabricated with technologies such as 3D printing and robotics. 
%
Landscapes and the built environment can be digitally fabricated 
with technologies such as machine control for construction, earthmoving, and precision agriculture 
%
Tangible interfaces for GIS have the potential to tie these emerging technologies together, seamlessly linking physical models, digital models, and real geographies. 

In the future we intend to extend Tangible Landscape to 
seamlessly, bidirectionally link a physical model, a digital model, and a real landscape.
%
We plan to integrate real-time streaming data, 
robotic fabrication, 
and automated construction 
to link real and virtual geographies via a tangible interface. 
%
We would stream real-time topographic data 
from sensors in the field -- such as unmanned aerial vehicles --
to a GIS for interpolation as a digital elevation model. 
%
A robotic arm would then rapidly update the physical model 
based on changes to the digital elevation model. 
%
Users could then explore potential changes by sculpting the physical model
and interacting with the real-time geospatial analyses and simulations. 
Finally, they could send a computationally optimized design 
to an autonomous construction vehicle or robot in the field for construction 
(Fig.~\ref{fig:system_schema_land}). 

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{images/system_schema_land.pdf}
\caption{Tangible Landscape with robotic fabrication, robotic construction, and real-time field data.}
\label{fig:system_schema_land}
\end{center}
\end{figure}

\section{Conclusion}
% concept
Tangible Landscape -- a tangible interface for GIS -- 
enables natural 3D sketching. % 4D spatiotemporal sketching.
%
Users can intuitively interact with 
spatial data and scientific models using their bodies. 
% 
% iterative process
By affording both natural, embodied interaction and analytical feedback
Tangible Landscape enables a
rapid iterative modeling process.
%
Through this embodied process of reflection-in-action 
users can 
observe spatial patterns, forms, and processes, 
generate and test hypotheses, 
and draw inferences. 
%
% experiment / findings
In a series of experiments we found that 
Tangible Landscape can improve spatial performance -- 
enabling users to more accurately model 3-dimensional space. 
%
The experiments show that users 
were able to offload enough of the cognitive work 
of sensing and manipulating space
onto their bodies
that they could understand the
computational analytics
and adaptively re-strategize.
%
% future research
Further experiments are needed
to explore the role of 
spatial cognition, affect, motivation, and metacognition 
in tangible modeling.


%% Appendix
%\appendix
%\section*{APPENDIX}
%\setcounter{section}{1}
%In this appendix \ldots

% Appendix
\appendixhead{HARMON}

%% Acknowledgments
%\begin{acks}
%\ldots
%\end{acks}

% Bibliography
\bibliographystyle{ACM-Reference-Format-Journals}
\bibliography{tangible_topography.bib}

% History dates
%\received{}{}{}

% Electronic Appendix
\elecappendix

\medskip

\section{How to build Tangible Landscape}\label{appendix:howto}

\begin{table}[H]
\tbl{Hardware}{
\ra{1.3}
\begin{tabular}{l l l}
\toprule
Type & Product & Cost\\
\midrule
Computer & System 76 Oryx Pro & \$1500\\
Projector & Optoma ML750 WXGA 700 DLP LED & \$500\\
3D sensor & Xbox One Kinect & \$100\\
& Kinect Adapter for Windows & \$50\\
Stand & Avenger 40-Inch C-Stand with Grip Kit & \$200\\
& Avenger 40-Inch C-Stand with Grip Kit & \$200\\
& Avenger F800 3-Inch Baby Wall Plate & \$10\\
& Avenger F800 3-Inch Baby Wall Plate & \$10\\
Peripherals & HDMI cable & \$10\\
& Extension cord & \$10\\
Modeling media & Waba Fun Kinetic Sand 11 Lbs & \$50\\
\bottomrule
\end{tabular}}
\label{table:hardware} 
\end{table}

\paragraph{Hardware}
To build Tangible Landscape you will need a computer,
a projector, a 3D sensor, an armature to hold the projector and sensor,
and a physical model of a landscape.
%
The computer should be
running Linux or Mac OS X and have
GRASS GIS,\footnote{
\url{https://grass.osgeo.org/}}
the grass-tangible-landscape plugin,\footnote{
\url{https://github.com/tangible-landscape/grass-tangible-landscape}}
the r.in.kinect add-on,\footnote{
\url{https://github.com/tangible-landscape/r.in.kinect}}
and their dependencies compiled. 

\paragraph{Physical models}
To sculpt with Tangible Landscape you need a malleable model 
made of a soft, deformable medium like polymer enriched sand. 
These models can be hand sculpted or precisely cast with digitally fabricated molds.
When you are using Tangible Landscape for object detection 
you can use hard, rigid models such as 3D prints. 

\paragraph{Setup}
Place your physical model of a landscape on a table. 
Mount the Kinect sensor on baby wall plate attached to a C-stand. 
Adjust the height of the C-stand so that the Kinect is 0.5 m - 1 m above the model. 
Check that the Kinect is level using an instrument like a spirit level.
Mount the projector on another baby wall plate attached to the other C-stand. 
Connect the Kinect and projector to your computer. 

\paragraph{Calibration}
Remove the model, clear the table, and then
run Tangible Landscapes' automatic calibration function
to account for the relative rotation of the scanner and the table.

\begin{figure}[H]
\begin{center}
		\includegraphics{images/system_setup.pdf}
	\caption{System setup}
	\label{fig:system_setup}
\end{center}
\end{figure}

\vfill
\pagebreak

\section{Experimental procedure}\label{appendix:procedure}

\subsection{Data}\label{appendix:data}
Acquire elevation data for your study landscape.
We used a 2013 airborne lidar survey of Wake County, North Carolina. 
Other sources for lidar point clouds and raster elevation data 
include the National Elevation Dataset,\footnote{
\url{https://viewer.nationalmap.gov}}
the United States Interagency Elevation Inventory,\footnote{
\url{https://coast.noaa.gov/inventory/}}
and the European Environment Agency's
Digital Elevation Model over Europe.\footnote{
\url{http://www.eea.europa.eu/data-and-maps/data/eu-dem}}
%
Import lidar data in GRASS GIS as vector points using the module v.in.lidar\footnote{
\url{https://grass.osgeo.org/grass72/manuals/v.in.lidar.html}}
and then interpolate with the module v.surf.rst.\footnote{
\url{https://grass.osgeo.org/grass72/manuals/v.surf.rst.html}}
%
Find regions of the same size with clearly defined morphological features 
for each experiment. 

When preparing data and running analyses use the following naming conventions.
%
Digital modeling,
analog modeling,
augmented modeling,
tangible modeling with the difference analytic,
and tangible modeling with the water flow analytic
will be experiments 1-5.
%
For each experiment 
save the corresponding reference digital elevation model
in the \emph{PERMANENT} mapset 
with the number of the experiment 
(i.e.~dem{\_}1, 
dem{\_}2, 
dem{\_}3, 
dem{\_}4, 
and dem{\_}5).
%
Save the results of each experiment in the \emph{data} mapset
with the participant's name, the type of data, and the experiment number
(i.e.~name{\_}dem{\_}number).

\subsection{Experiments}\label{appendix:experiments}
Introduce the research and explain the experiment to each participants. 
If they agree to take part in the experiment have them sign an informed consent form.
%
\paragraph{Digital modeling}
In the \nth{1} experiment participants will sit at a computer
and use Rhinoceros, a 3D modeling program, to digitally model
the study landscape. 

% 10 minutes of training

% 10 minutes of modeling

%
\paragraph{Tangible Landscape}
%In experiment 2-5 participants will build polymer-enriched sand models 

% observation, photography, and video
%Record the experiments with photographic 
% interviews
Interview select participants after the experiment. 
See Appendix \ref{appendix:guidelines} for semi-structured interview guidelines.

\subsection{Geospatial analysis}\label{appendix:analysis}
Copy the scanned maps from the \emph{data} mapset 
to a new \emph{analysis} mapset for processing. 
Open a session of GRASS GIS 
in the appropriate location (i.e.~\emph{experiment{\_ncspf}}) 
with the \emph{analysis} mapset.
Create new directories \emph{results} and \emph{render\_3d} 
inside the location directory.
Run the script \emph{analysis.py} in this GRASS session to analyze the data. 
This will generate new maps with analyses and simulations in the \emph{analysis} mapset
and will render the maps as \emph{.png} images in the \emph{results} directory.
Then run the script \emph{render\_3d\_images.py} 
to generate 3D renderings of the maps in the \emph{render\_3d} directory.

\vfill
\pagebreak

\section{Semi-structured interview guidelines}\label{appendix:guidelines}
\vspace*{0.5em}

\subsection{Aim}
Understand how tangible interfaces for geospatial modeling change how users model.
\vspace*{0.5em}

\subsection{Interview goals}
\begin{itemize}
\item Map participants' analog, hand modeling processes
\item Map participants' digital modeling processes
\item Map participants' augmented modeling processes
\item Map participants' tangible modeling processes with the difference analytic
\item Map participants' tangible modeling processes with the water flow analytic
\end{itemize}
\vspace*{0.5em}

\subsection{\emph{Topic:} Modeling process}
\begin{itemize}
\item Please describe your modeling process with each technology
\item Did you work additively or subtractively? A mix?
\item Did you work in a linear or iterative, exploratory process?
\item How did this technology aid you? What did it let you to do?
\item Did this technology constrain you in any way?
\end{itemize}
\vspace*{0.5em}

\subsection{\emph{Topic:} Intuition}
\begin{itemize}
\item How intuitive was it? 
\item Could you model what you intended?
\item Did you have to think about how to modeling? Or could you just act?
\end{itemize}
\vspace*{0.5em}

\subsection{\emph{Topic:} Metacognition}
\begin{itemize}
\item We asked you to sculpt a model of the study landscape. Please describe your thought process while sculpting. 
\item Did you strategize about how to model? If so what was your modeling strategy? 
\item Did your modeling strategy evolve as you worked?
\end{itemize}
\vspace*{0.5em}

\subsection{Topic: perception and experience}
\begin{itemize}
\item How did it feel to sculpt a 3D model with this technology?
\item Was it stressful? Was it fun?
\item Did the technology change how you perceived distance, depth, form, or volume?  
\end{itemize}

\vfill

%\pagebreak
%
%\section{Interview notes}
%%
%\subsection{Interview I}
%%
%\paragraph{Digital modeling}
%Understanding how Rhino works 
%-- i.e.~the underlying mathematical representation, NURBS -- is very important. 
%Once you understand that is a tension field 
%then you understand how to shape it, how to make it do what you want.
%%
%\paragraph{Tangible modeling}
%We all already understand how sand works. 
%We understand sand, but not necessarily these analytics 
%-- the difference analytic or the water flow simulation.
%
%\subsection{Interview II}
%\paragraph{Digital modeling}
%Working in Vue is like modeling in wax.
%Working with multiple tools in Vue gave me more control, more options
%than Rhino's gumball did. It is easier than Rhino.
%Even though it is easy it is still very important to learn the tools.
%I was exploring what the tools could do.
%%
%\paragraph{Analog, hand modeling}
%I worked additively, then subtractively, smoothing.
%The sculpting tool gave sharpness --
%the sharp edge let me smooth in a way my fingers couldn't.
%It felt like drawing or laying concrete.
%Feeling is important -- I could feel subtle changes in topography.
%%
%\paragraph{Projection augmented modeling}
%I worked additively. 
%I sculpted with my fingers rather than the wooden modeling tool. 
%The projection helped to orient me  
%by defining features like the shoreline.
%%
%\paragraph{Tangible modeling}
%The water flow analytic reminds of me of playing in creeks and grading streams as a kid. 
%
%\subsection{Interview III}
%%
%\paragraph{Digital modeling}
%Digital modeling has a long learning curve. 
%It was not intuitive. I was quite anxious. 
%The interaction was quite abstract, quite indirect 
%-- I was moving points to change the surface.
%Working with the surface was like draping a fabric.
%%
%\paragraph{Analog, hand modeling}
%My sense of touch took away the mystery of topography.
%I could sculpt like reading braille. I could feel the shape with my fingers.
%It was intuitive and calming. 
%%
%\paragraph{Projection augmented modeling}
%With the projected maps draped over the sand
%there were layers of systems, strata overlaid.
%%
%\paragraph{Tangible modeling}
%The difference analytic was the best. 
%I tried to make it match. 
%I was constantly rebuilding to make it match.
%The water flow analytic was useful for thinking about form, 
%about what form does --  why water flows where it does.
%Seeing the flow takes away the mystery of topography.
%Our students tend to have a linear design process.
%Because Tangible Landscape gives immediate results 
%it encourages an iterative process.
%
%\subsection{Interview IV}
%%
%\paragraph{Digital modeling}
%My strategy was to model the outside borders first. 
%Then the interior. 
%%
%\paragraph{Analog, hand modeling}
%I have done lots of sculpture so
%I knew how to feel the shape of the model. 
%And the desk lamp cast shadows so I could visually perceive depth.
%%
%\paragraph{Projection augmented modeling}
%The contours were just a guide. 
%My general strategy was additive. 
%I felt with my hands to try to match the contours. 
%If I saw concavity in the contours 
%then I felt the sand and sculpted that concavity.
%Finding the relative height, however, was challenging -- it was subtle.
%Most people don't understand contours. 
%They have to be taught. 
%
%\subsection{Interview IV}
%%
%\paragraph{Tangible modeling}
%Tangible Landscape let me tinker. 
%I could rapidly create, making new iterations. 
%I could try something, see and feel it -- directly experience it --
%and try again. Reinvent it.
%Tinkering like this is a learning process. Learning through doing.
%Tangible Landscape lowers the stakes so that you're not too invested.
%You're ready to fail. So you can intuitively explore, 
%while reflecting on what you've done,
%what you're doing.
%
%\vfill

\end{document}
